{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2020.2.12 11:00\n",
    "@author: Johnson\n",
    "\n",
    "\"\"\"\n",
    "from ckiptagger import data_utils, construct_dictionary, WS,POS, NER\n",
    "import csv\n",
    "import logging\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# 載入 ckiptagger 自訂詞典\n",
    "User_Dict = {}\n",
    "with open(\"KCC Data/Dict/KccDict2020.txt\",\"r\", encoding='utf-8-sig') as UDicts:\n",
    "    for udic in UDicts:\n",
    "        udWord = udic.strip().split(\" \")\n",
    "        if len(udWord) > 1:\n",
    "            User_Dict[udWord[0]] = udWord[1]\n",
    "        else:\n",
    "            User_Dict[udWord[0]] = 10    # 未給定權重者一律賦予預設值 10                \n",
    "dictionary = construct_dictionary(User_Dict)\n",
    "\n",
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "ner = NER(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x1abbc7884a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvIn = open(\"KCC Data/News-CIS Data/NewsCis18850.csv\", 'r', newline='', encoding='utf-8-sig')\n",
    "#for row in csvIn:\n",
    "    #print(row)\n",
    "\n",
    "rowlists = csv.reader(csvIn)\n",
    "rowlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------CKIPTagger Word Segment ws(str,....) + 合併同義字 + 刪除標點及停用字 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-01 14:49:46,752 : INFO : 已完成CkipCis  11 檔案 的斷詞\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4bce938adb06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                    \u001b[0msentence_segmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                    \u001b[0msegment_delimiter_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\\r\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"，\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"「\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"」\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"？\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"。\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"?\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"!\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"、\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                    coerce_dictionary = dictionary)\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstrCut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# 合併同義字\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\ckiptagger\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, sentence_list, recommend_dictionary, coerce_dictionary, sentence_segmentation, segment_delimiter_set, character_normalization, batch_sentences, batch_characters)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0mparital_seq_segment_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[0mparital_seq_segment_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_label_for_a_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpartial_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mseq_segment_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparital_seq_segment_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartial_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\ckiptagger\\model_ws.py\u001b[0m in \u001b[0;36mpredict_label_for_a_batch\u001b[1;34m(self, sample_list)\u001b[0m\n\u001b[0;32m    415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             }\n\u001b[0;32m    419\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cc518\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "csvIn = open(\"KCC Data/News-CIS Data/NewsCis18850.csv\", 'r', newline='', encoding='utf-8-sig')\n",
    "output1 = open(\"KCC Data/News-CIS Data/NewsCis18850Test.txt\", 'w', encoding='utf-8-sig')\n",
    "\n",
    "# 載入同義字(ex黃捷=黃議員捷等等)\n",
    "combine_dict = {}\n",
    "for line in open(\"KCC Data/Dict/KccSynonym2020.txt\", \"r\", encoding=\"utf-8-sig\"):  \n",
    "    seperate_word = line.strip().split(\"\\t\")\n",
    "    num = len(seperate_word)\n",
    "    for i in range(1, num):\n",
    "        combine_dict[seperate_word[i]] = seperate_word[0] #任何多數個同義字都會等於第一個(以第一個名稱為代表)\n",
    "\n",
    "# 載入 StopWord\n",
    "stopword_lst = []\n",
    "with open(\"KCC Data/Dict/KccStopWord2020.txt\",\"r\", encoding='utf-8-sig') as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_lst.append(stopword.strip())\n",
    "\n",
    "print(\"------------CKIPTagger Word Segment ws(str,....) + 合併同義字 + 刪除標點及停用字 ---------------\")\n",
    "rowlists = csv.reader(csvIn)\n",
    "i = 0\n",
    "for row in rowlists:\n",
    "    # 刪除標點, 使用自訂強制詞典\n",
    "    strCut = ws([row[2]], \n",
    "                   sentence_segmentation=True,\n",
    "                   segment_delimiter_set = {'\"',\"\\r\\n\",\"，\",\"「\",\"」\",\",\",\"？\",'\\n', \"。\", \":\", \"?\", \"!\", \";\", \"、\"},\n",
    "                   coerce_dictionary = dictionary)\n",
    "    for word in strCut[0]:\n",
    "        # 合併同義字\n",
    "        if word in combine_dict:\n",
    "            word = combine_dict[word]\n",
    "        \n",
    "        # 刪除停用字\n",
    "        if word not in stopword_lst:\n",
    "            output1.write(word + ' ')\n",
    "    output1.write('\\n')                \n",
    "    i += 1\n",
    "    if i % 10 == 0:\n",
    "        logging.info(\"已完成CkipCis  %d 檔案 的斷詞\" % (i + 1))\n",
    "output1.close()\n",
    "csvIn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>馬英九 昨天 上午 視察 衛武營藝術文化中心 文化部 長 洪孟啟 工程 副主委 顏久榮 高雄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>日本 九州熊本 縣 接連 遭 強震 襲擊 台灣 捐贈 熊本 縣政府 日本 政府 款項 高雄市...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>壽山動物園 增進 動物飼養 福祉 保育 工作 特 設立 高雄市壽山動物園動物認養辦法 設立 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>日本 熊本地震 災情 慘重 高雄市 長 陳菊 昨天 說 率先 捐出 一月 所得 指示 市府 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>睽違 超過 世紀 緬甸 官方 代表 行 包含 位 緬甸 聯邦 議會 議員 美國 農村 發展 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>高雄 翻轉 須 新 政府 力挺 高雄市 長 陳菊 日前 高雄市議會 做 施政報告 時 指出 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>高雄市 長 陳菊 昨 前往 東台 精機 參訪 高雄 鼓勵 傳統 產業 升級 研發 提升 產業...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>交通局 委託 民間 公司 民調 昨天 公布 民調 月 搭乘 公車 民眾 滿意度 高達 九十三...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>臺灣塑膠工業股份有限公司 企業 回饋 地方 藝文 活動 週六 晚間 高雄市 仁武運動公園 登...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中國國民黨 分區 立委 陳宜民 鳳山 地區 成立 聯合 服務處 日前 揭 牌 成立 服務處 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>高雄 年 破產 苗栗縣 發 薪水 破產 引發 全民 關注 債台高 築 高雄市 苗栗縣 高雄市...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>談 赦扁 暗 公鳥 特赦 陳水扁 呼聲 台南 高雄市議會 醫界 相繼 呼籲 馬英九 特赦 陳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   馬英九 昨天 上午 視察 衛武營藝術文化中心 文化部 長 洪孟啟 工程 副主委 顏久榮 高雄...\n",
       "1   日本 九州熊本 縣 接連 遭 強震 襲擊 台灣 捐贈 熊本 縣政府 日本 政府 款項 高雄市...\n",
       "2   壽山動物園 增進 動物飼養 福祉 保育 工作 特 設立 高雄市壽山動物園動物認養辦法 設立 ...\n",
       "3   日本 熊本地震 災情 慘重 高雄市 長 陳菊 昨天 說 率先 捐出 一月 所得 指示 市府 ...\n",
       "4   睽違 超過 世紀 緬甸 官方 代表 行 包含 位 緬甸 聯邦 議會 議員 美國 農村 發展 ...\n",
       "5   高雄 翻轉 須 新 政府 力挺 高雄市 長 陳菊 日前 高雄市議會 做 施政報告 時 指出 ...\n",
       "6   高雄市 長 陳菊 昨 前往 東台 精機 參訪 高雄 鼓勵 傳統 產業 升級 研發 提升 產業...\n",
       "7   交通局 委託 民間 公司 民調 昨天 公布 民調 月 搭乘 公車 民眾 滿意度 高達 九十三...\n",
       "8   臺灣塑膠工業股份有限公司 企業 回饋 地方 藝文 活動 週六 晚間 高雄市 仁武運動公園 登...\n",
       "9   中國國民黨 分區 立委 陳宜民 鳳山 地區 成立 聯合 服務處 日前 揭 牌 成立 服務處 ...\n",
       "10  高雄 年 破產 苗栗縣 發 薪水 破產 引發 全民 關注 債台高 築 高雄市 苗栗縣 高雄市...\n",
       "11  談 赦扁 暗 公鳥 特赦 陳水扁 呼聲 台南 高雄市議會 醫界 相繼 呼籲 馬英九 特赦 陳..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv(\"KCC Data/News-CIS Data/NewsCis18850Test.txt\",header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------CKIPTagger pos(str,....) ---------------------\n",
      "[['D', 'VE', 'VH', 'VH', 'Na', 'D', 'VC', 'Nb', 'Na', 'VH', 'COMMACATEGORY', 'Nc', 'Caa', 'Nc', 'Caa', 'Nc', 'D', 'VE', 'Nb', 'VC', 'Nb', 'PERIODCATEGORY', 'Na', 'SHI', 'Na', 'COMMACATEGORY', 'P', 'Nh', 'VA', 'VC', 'Na', 'D', 'D', 'VG', 'VH', 'COMMACATEGORY', 'Cbb', 'Nh', 'Nh', 'VJ', 'Na', 'COMMACATEGORY', 'D', 'VJ', 'Na', 'DE', 'Na', 'COMMACATEGORY', 'VE', 'Na', 'VH', 'VK', 'SHI', 'Na', 'VA', 'COMMACATEGORY', 'D', 'VH', 'T', 'PERIODCATEGORY', 'Na', 'VC', 'Na', 'SHI', 'Neu', 'Nf', 'Na', 'PAUSECATEGORY', 'D', 'SHI', 'Neu', 'Nf', 'VJ', 'Na', 'PERIODCATEGORY', 'P', 'Na', 'Na', 'VC', 'COMMACATEGORY', 'VC', 'D', 'P', 'VE', 'SHI', 'VJ', 'VJ', 'Na', 'COMMACATEGORY', 'Cbb', 'VH', 'Ng', 'Na', 'DE', 'VC', 'D', 'SHI', 'VJ', 'Na', 'VE', 'COMMACATEGORY', 'VA', 'Na', 'P', 'VJ', 'D', 'VC', 'Na', 'PAUSECATEGORY', 'VHC', 'Na', 'VH', 'COMMACATEGORY', 'VC', 'VH', 'VH', 'VH', 'DE', 'VK', 'PERIODCATEGORY', 'P', 'COMMACATEGORY', 'Nd', 'Ng', 'COMMACATEGORY', 'Nc', 'Na', 'VH', 'Nb', 'VC', 'Di', 'Nes', 'Na', 'Cab', 'Neu', 'Nf', 'VK', 'Na', 'Na', 'PARENTHESISCATEGORY', 'FW', 'PARENTHESISCATEGORY', 'DE', 'Na', 'COMMACATEGORY', 'Nd', 'Nes', 'Na', 'FW', 'FW', 'DOTCATEGORY', 'FW', 'D', 'P', 'VC', 'COMMACATEGORY', 'VK', 'VC', 'PERIODCATEGORY', 'Nb', 'Na', 'VE', 'VC', 'Na', 'SHI', 'D', 'VC', 'Na', 'PAUSECATEGORY', 'VHC', 'Na', 'VH', 'PERIODCATEGORY', 'Nb', 'Na', 'VH', 'DE', 'VHC', 'Di', 'D', 'VA', 'DE', 'Na', 'COMMACATEGORY', 'D', 'Na', 'DE', 'VC', 'Di', 'Na', 'Na', 'COMMACATEGORY', 'P', 'Nep', 'COMMACATEGORY', 'Nd', 'DE', 'Na', 'Nb', 'D', 'VC', 'VH', 'Na', 'PERIODCATEGORY', 'Nd', 'Nd', 'Nb', 'Cbb', 'Na', 'VL', 'VA', 'VA', 'COMMACATEGORY', 'Na', 'Nb', 'VC', 'VH', 'Nd', 'D', 'P', 'Na', 'VC', 'VH', 'Na', 'DE', 'Na', 'COMMACATEGORY', 'VE', 'D', 'Na', 'PARENTHESISCATEGORY', 'FW', 'PARENTHESISCATEGORY', 'COMMACATEGORY', 'VC', 'Nb', 'VH', 'Na', 'D', 'D', 'VC', 'DE', 'Neqa', 'Na', 'PERIODCATEGORY', 'Nb', 'Na', 'P', 'Nb', 'VC', 'Di', 'D', 'VC', 'DE', 'Na', 'VA', 'Na', 'COMMACATEGORY', 'D', 'D', 'VC', 'Di', 'Na', 'VH', 'Caa', 'Na', 'Na', 'DE', 'VC', 'PERIODCATEGORY', 'P', 'Na', 'Na', 'VE', 'COMMACATEGORY', 'Nb', 'Na', 'Caa', 'Nb', 'Na', 'D', 'VH', 'VC', 'Na', 'PARENTHESISCATEGORY', 'FW', 'FW', 'FW', 'PARENTHESISCATEGORY', 'COMMACATEGORY', 'Cbb', 'Nh', 'D', 'D', 'VE', 'VA', 'COMMACATEGORY', 'Nh', 'SHI', 'P', 'VC', 'Na', 'D', 'VC', 'Na', 'PERIODCATEGORY', 'Na', 'Na', 'Na', 'VJ', 'Na', 'Na', 'COMMACATEGORY', 'FW', 'FW', 'Nb', 'Caa', 'Nb', 'P', 'VC', 'Ng', 'D', 'SHI', 'VH', 'DE', 'Na', 'PERIODCATEGORY', 'Nb', 'D', 'VC', 'Na', 'COMMACATEGORY', 'D', 'V_2', 'VH', 'DE', 'Na', 'PAUSECATEGORY', 'D', 'VC', 'Na', 'Na', 'COMMACATEGORY', 'Cbb', 'Nb', 'DE', 'Na', 'VJ', 'Na', 'VC', 'COMMACATEGORY', 'VC', 'VJ', 'Nb', 'Na', 'DE', 'Nv', 'COMMACATEGORY', 'Cbb', 'VC', 'Na', 'D', 'Dfa', 'VK', 'Nb', 'SHI', 'Nc', 'Na', 'Na', 'DE', 'VJ', 'Na', 'PERIODCATEGORY', 'Dk', 'Nb', 'P', 'VHC', 'Na', 'VH', 'Cbb', 'VC', 'Na', 'COMMACATEGORY', 'Cbb', 'VHC', 'Di', 'Na', 'COMMACATEGORY', 'VL', 'D', 'Cbb', 'Na', 'Cbb', 'VH', 'DE', 'Nc', 'Na', 'Dfa', 'VHC', 'PERIODCATEGORY', 'Cbb', 'Na', 'VJ', 'Neu', 'Nf', 'Ng', 'COMMACATEGORY', 'Nb', 'Nh', 'D', 'VK', 'Nh', 'Nd', 'VC', 'Nb', 'SHI', 'VH', 'DE', 'Na', 'Na', 'COMMACATEGORY', 'Cbb', 'VE', 'Dfa', 'VH', 'DE', 'Nb', 'Nb', 'Na', 'Nb', 'Nb', 'D', 'D', 'VC', 'Na', 'COMMACATEGORY', 'VK', 'Nb', 'Nd', 'DE', 'Na', 'VC', 'Di', 'Na', 'VH', 'D', 'VC', 'DE', 'Na', 'COMMACATEGORY', 'D', 'VL', 'Na', 'D', 'P', 'Ncd', 'VA', 'PERIODCATEGORY', 'Na', 'VH', 'DE', 'Na', 'VG', 'D', 'P', 'Nc', 'VG', 'FW', 'FW', 'Na', 'DE', 'Nb', 'Na', 'VC', 'Di', 'Neu', 'Nf', 'Dfa', 'VH', 'DE', 'Na', 'Na', 'PERIODCATEGORY', 'VC', 'Na', 'DE', 'FW', 'FW', 'Nb', 'COMMACATEGORY', 'Cbb', 'V_2', 'Nb', 'Caa', 'Nc', 'Na', 'D', 'VC', 'VH', 'Na', 'COMMACATEGORY', 'Nh', 'D', 'VE', 'Nh', 'D', 'Na', 'VK', 'VH', 'COMMACATEGORY', 'Nep', 'D', 'D', 'VL', 'Na', 'VK', 'COMMACATEGORY', 'D', 'VH', 'VK', 'V_2', 'Na', 'Na', 'Caa', 'VH', 'DE', 'Na', 'PERIODCATEGORY', 'P', 'Neu', 'Nf', 'Na', 'VC', 'Na', 'PAUSECATEGORY', 'D', 'D', 'VC', 'Na', 'Na', 'DE', 'Na', 'D', 'VE', 'COMMACATEGORY', 'VJ', 'VA', 'D', 'D', 'VC', 'DE', 'Na', 'Na', 'D', 'VG', 'Na', 'PERIODCATEGORY', 'Nh', 'DE', 'Na', 'Nh', 'VC', 'PERIODCATEGORY', 'Na', 'Nb', 'D', 'VK', 'COMMACATEGORY', 'Na', 'Na', 'SHI', 'VA', 'Nb', 'Nc', 'COMMACATEGORY', 'D', 'SHI', 'VH', 'VE', 'Caa', 'Na', 'DE', 'Na', 'PERIODCATEGORY', 'Nb', 'SHI', 'Nf', 'Na', 'Na', 'COMMACATEGORY', 'D', 'VC', 'Nep', 'Nd', 'Na', 'DE', 'Da', 'V_2', 'Nh', 'Na', 'Neu', 'Nf', 'Na', 'PERIODCATEGORY', 'Na', 'VH', 'D', 'D', 'D', 'SHI', 'Na', 'Na', 'COMMACATEGORY', 'Cbb', 'VH', 'DE', 'Na', 'COMMACATEGORY', 'D', 'VC', 'Nep', 'Nf', 'Na', 'D', 'P', 'Na', 'Na', 'PERIODCATEGORY', 'VG', 'Na', 'DE', 'Nb', 'D', 'D', 'VC', 'Na', 'Nb', 'Na', 'COMMACATEGORY', 'P', 'VC', 'VH', 'VH', 'VH', 'PAUSECATEGORY', 'VC', 'VH', 'Na', 'Na', 'PAUSECATEGORY', 'Caa', 'Na', 'VE', 'COMMACATEGORY', 'Cbb', 'VK', 'Nb', 'Nd', 'Ng', 'D', 'VC', 'DE', 'Na', 'Caa', 'Nh', 'Nd', 'D', 'D', 'VC', 'DE', 'Na', 'COMMACATEGORY', 'D', 'VC', 'Nb', 'PERIODCATEGORY', 'D', 'D', 'VL', 'Na', 'VL', 'VH', 'Di', 'Cbb', 'VG', 'VH', 'DE', 'Na', 'Na', 'COMMACATEGORY', 'VC', 'Nc', 'PERIODCATEGORY']]\n",
      "------------CKIPTagger ner(str,....) ---------------------\n",
      "[{(21, 26, 'ORG', '高雄市議會'), (197, 199, 'GPE', '美國'), (710, 713, 'EVENT', '水門案'), (732, 736, 'DATE', '三十年後'), (252, 270, 'PERSON', 'CasparW.Weinberger'), (439, 441, 'ORG', '福特'), (491, 493, 'ORG', '福特'), (749, 752, 'PERSON', '尼克森'), (1060, 1061, 'PERSON', '扁'), (845, 847, 'ORG', '福特'), (33, 36, 'PERSON', '馬英九'), (667, 670, 'ORG', '華盛頓'), (346, 349, 'PERSON', '克林頓'), (407, 417, 'PERSON', 'fullpardon'), (628, 630, 'ORG', '福特'), (788, 790, 'ORG', '福特'), (208, 212, 'ORG', '國防部長'), (38, 41, 'PERSON', '陳水扁'), (201, 204, 'PERSON', '老布希'), (1110, 1112, 'ORG', '福特'), (719, 721, 'GPE', '美國'), (356, 363, 'DATE', '一九七四年八月'), (11, 13, 'PERSON', '阿扁'), (547, 549, 'LAW', '憲法'), (222, 240, 'PERSON', 'Iran-contrascandal'), (496, 498, 'PERSON', '布希'), (1103, 1105, 'PERSON', '小英'), (1143, 1145, 'PERSON', '阿扁'), (363, 366, 'PERSON', '尼克森'), (587, 590, 'PERSON', '尼克森'), (663, 666, 'PERSON', '尼克森'), (774, 780, 'PERSON', '愛德華甘迺迪'), (879, 882, 'PERSON', '馬英九'), (18, 20, 'GPE', '台南'), (190, 196, 'DATE', '一九九二年底'), (768, 771, 'ORG', '民主黨'), (737, 739, 'ORG', '福特'), (444, 447, 'PERSON', '尼克森'), (644, 647, 'PERSON', '尼克森'), (305, 308, 'PERSON', '布希特'), (1170, 1173, 'PERSON', '陳水扁'), (213, 214, 'CARDINAL', '五'), (367, 370, 'EVENT', '水門案'), (248, 252, 'ORG', '國防部長'), (380, 382, 'PERSON', '福特'), (681, 683, 'ORG', '福特'), (866, 868, 'GPE', '台灣'), (942, 943, 'CARDINAL', '一'), (280, 282, 'PERSON', '布希'), (384, 386, 'DATE', '滿月'), (386, 388, 'DATE', '當天'), (421, 424, 'PERSON', '尼克森'), (745, 747, 'DATE', '當年'), (601, 603, 'ORG', '福特'), (1000, 1003, 'PERSON', '蔡英文'), (568, 586, 'PERSON', 'CasparW.Weinberger')}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "860212"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"------------CKIPTagger pos(str,....) ---------------------\")\n",
    "pos_sentence_list = pos(strCut)\n",
    "print(pos_sentence_list)\n",
    "\n",
    "print(\"------------CKIPTagger ner(str,....) ---------------------\")\n",
    "entity_sentence_list = ner(strCut, pos_sentence_list)\n",
    "\n",
    "print(entity_sentence_list)\n",
    "\n",
    "del ws\n",
    "del WS\n",
    "del pos\n",
    "del POS\n",
    "del ner\n",
    "del NER\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
